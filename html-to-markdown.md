ol.lst-kix\_2lk9b54ye20-4.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-4 0}.lst-kix\_2lk9b54ye20-0>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-0,decimal) ") "}.lst-kix\_2lk9b54ye20-4>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-4}.lst-kix\_2lk9b54ye20-1>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-1}.lst-kix\_2lk9b54ye20-3>li:before{content:"(" counter(lst-ctn-kix\_2lk9b54ye20-3,decimal) ") "}.lst-kix\_2lk9b54ye20-7>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-7}.lst-kix\_2lk9b54ye20-4>li:before{content:"(" counter(lst-ctn-kix\_2lk9b54ye20-4,lower-latin) ") "}.lst-kix\_2lk9b54ye20-5>li:before{content:"(" counter(lst-ctn-kix\_2lk9b54ye20-5,lower-roman) ") "}ol.lst-kix\_2lk9b54ye20-1.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-1 0}.lst-kix\_2lk9b54ye20-2>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-2,lower-roman) ") "}.lst-kix\_2lk9b54ye20-8>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-8}.lst-kix\_2lk9b54ye20-1>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-1,lower-latin) ") "}ol.lst-kix\_2lk9b54ye20-6.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-6 0}ol.lst-kix\_2lk9b54ye20-3.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-3 0}ol.lst-kix\_2lk9b54ye20-5.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-5 0}.lst-kix\_2lk9b54ye20-5>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-5}.lst-kix\_2lk9b54ye20-2>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-2}li.li-bullet-0:before{margin-left:-18pt;white-space:nowrap;display:inline-block;min-width:18pt}ol.lst-kix\_2lk9b54ye20-8.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-8 0}ol.lst-kix\_2lk9b54ye20-0{list-style-type:none}ol.lst-kix\_2lk9b54ye20-1{list-style-type:none}.lst-kix\_2lk9b54ye20-6>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-6,decimal) ". "}.lst-kix\_2lk9b54ye20-7>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-7,lower-latin) ". "}ol.lst-kix\_2lk9b54ye20-2{list-style-type:none}ol.lst-kix\_2lk9b54ye20-3{list-style-type:none}.lst-kix\_2lk9b54ye20-6>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-6}ol.lst-kix\_2lk9b54ye20-0.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-0 0}.lst-kix\_2lk9b54ye20-0>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-0}ol.lst-kix\_2lk9b54ye20-4{list-style-type:none}ol.lst-kix\_2lk9b54ye20-5{list-style-type:none}ol.lst-kix\_2lk9b54ye20-6{list-style-type:none}ol.lst-kix\_2lk9b54ye20-7{list-style-type:none}ol.lst-kix\_2lk9b54ye20-7.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-7 0}ol.lst-kix\_2lk9b54ye20-8{list-style-type:none}ol.lst-kix\_2lk9b54ye20-2.start{counter-reset:lst-ctn-kix\_2lk9b54ye20-2 0}.lst-kix\_2lk9b54ye20-8>li:before{content:"" counter(lst-ctn-kix\_2lk9b54ye20-8,lower-roman) ". "}.lst-kix\_2lk9b54ye20-3>li{counter-increment:lst-ctn-kix\_2lk9b54ye20-3}ol{margin:0;padding:0}table td,table th{padding:0}.c1{background-color:#ffffff;color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Courier New";font-style:normal}.c5{padding-top:14pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c11{padding-top:16pt;padding-bottom:4pt;line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.c3{color:#000000;font-weight:400;text-decoration:none;vertical-align:baseline;font-size:11pt;font-family:"Courier New";font-style:normal}.c4{padding-top:0pt;padding-bottom:0pt;line-height:1.5;orphans:2;widows:2;text-align:left}.c0{padding-top:0pt;padding-bottom:0pt;line-height:1.15;orphans:2;widows:2;text-align:left}.c16{color:#434343;font-weight:400;font-size:14pt;font-family:"Arial"}.c12{color:#000000;font-weight:400;font-size:11pt;font-family:"Arial"}.c14{color:#434343;font-weight:700;font-size:14pt;font-family:"Courier New"}.c8{font-size:11pt;font-family:"Courier New";color:#000000;font-weight:700}.c9{text-decoration:none;vertical-align:baseline;font-style:normal}.c13{color:#000000;font-size:10pt}.c15{font-weight:700;font-family:"Courier New"}.c18{max-width:451.4pt;padding:72pt 72pt 72pt 72pt}.c19{padding:0;margin:0}.c17{color:#434343;font-size:14pt}.c6{margin-left:36pt;padding-left:0pt}.c7{font-weight:400;font-family:"Courier New"}.c10{background-color:#ffffff}.c2{height:11pt}.title{padding-top:0pt;color:#000000;font-size:26pt;padding-bottom:3pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}.subtitle{padding-top:0pt;color:#666666;font-size:15pt;padding-bottom:16pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}li{color:#000000;font-size:11pt;font-family:"Arial"}p{margin:0;color:#000000;font-size:11pt;font-family:"Arial"}h1{padding-top:20pt;color:#000000;font-size:20pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h2{padding-top:18pt;color:#000000;font-size:16pt;padding-bottom:6pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h3{padding-top:16pt;color:#434343;font-size:14pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h4{padding-top:14pt;color:#666666;font-size:12pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h5{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;orphans:2;widows:2;text-align:left}h6{padding-top:12pt;color:#666666;font-size:11pt;padding-bottom:4pt;font-family:"Arial";line-height:1.15;page-break-after:avoid;font-style:italic;orphans:2;widows:2;text-align:left}

\# library(SVDFunctions)

\# library(dplyr)

\# The code below has been performed for GBR sampleset

### \# Generate genotype matrix

variants <- read.table("one\_consequence.tsv", header=TRUE, sep="\\t")

1 476 344 rows #annotation file from vep

vars <- paste(paste(paste("chr", variants$chr, sep = ""), variants$pos, sep = ":"), variants$ref, variants$alt, sep = "\\t")

samples <- scan("intersected\_samples.txt", what = character())

read 91 samples #read samples

result <- SVDFunctions::scanBinaryFile(“new\_bin\_bin”, “new\_bin\_meta”, samples = samples, vars = vars, DP = 0, GQ = 0)

### \# Generate merged file of annotaion and genotype distribution of samples

variants <- as.data.frame(cbind(vars, variants))

master\_table <- inner\_join(result, variants)

161558 rows

### \# Calculate the internal allele frequency

master\_table$internal\_af <- (master\_table$het + master\_table$hom\_alt\*2) / 182 (n\_samples\*2)

### \# Calculate the variance between gnomAD and internal frequencies

master\_table$var <- master\_table$internal\_af - master\_table$freq

### \# Allele frequency filtering

#### \# Firstly, we can apply basic filters, dividing our data by variant annotation

\# synonymous variants:

master\_syns <- master\_table %>% filter(reason == “synonymous\_variant”)

\# missense+ptv variants:

master\_mis\_ptv <- master\_table %>% filter(reason == "missense\_variant" | reason == "frameshift\_variant" | reason == "stop\_gained" | reason == "stop\_lost" | reason == "splice\_acceptor\_variant" | reason == "splice\_donor\_variant" | reason == "start\_lost")

#### \# Then, we need to perform filtering and get variants we actually want to work with. It will include:

1.  calculator variance between gnomAD allele frequency and internal allele frequency
2.  filtering by |variance| <= 2\*std of this variance
3.  filtering by gnomAD allele frequency
4.  filtering by internal allele frequency

\# This should help in filtering discordant variants

\# synonymous variants:

master\_syns\_1p\_filt <- master\_syns %>% filter((freq <= 0.01 & freq !=0) & internal\_af <= 0.01 & (var <= 2\*sd(master\_table$var) & var >= -2\*sd(master\_table$var))

\# missense+ptv variants:

master\_mis\_ptv\_1p\_filt <- master\_mis\_ptv %>% filter((freq <= 0.01 & freq !=0) & internal\_af <= 0.01 & (var <= 2\*sd(master\_table$var) & var >= -2\*sd(master\_table$var))

### \# Platform parameters: DP=0, GQ=0, gnomAD\_MAF = 0.01, отдельно syn, отдельно mis+ptv

### \# Group variants by gene

\# synonymous variants:

master\_1p\_syns\_gr <- master\_syns\_1p\_filt %>%                                                                                                   group\_by(gene) %>%

  summarise(

    hom\_ref = sum(hom\_ref, na.rm = TRUE),

    het = sum(het, na.rm = TRUE),

    hom\_alt = sum(hom\_alt, na.rm = TRUE),

    n\_variants = sum(n\_variants, na.rm = TRUE),

    call\_rate = mean(call\_rate, na.rm = TRUE)

  )

\# missense+ptv variants:

master\_1p\_mis\_ptv\_gr <- master\_mis\_ptv\_1p\_filt %>%                                                                                                   group\_by(gene) %>%

  summarise(

    hom\_ref = sum(hom\_ref, na.rm = TRUE),

    het = sum(het, na.rm = TRUE),

    hom\_alt = sum(hom\_alt, na.rm = TRUE),

    n\_variants = sum(n\_variants, na.rm = TRUE),

    call\_rate = mean(call\_rate, na.rm = TRUE)

  )

### \# Import files from platform

\# synonymous variants:

syns\_controls\_1p <- read.table("syns\_genes\_controls\_1p.tsv", header=TRUE, sep="\\t")

\# missense+ptv variants:

mis\_ptv\_controls\_1p <- read.table("mis\_ptv\_genes\_controls\_1p.tsv", header=TRUE, sep="\\t")

### \# Merge cases matrix and controls matrix

\# Cases samples get the flag ‘\_test’

\# synonymous variants:

merged\_data\_syns\_1p <- merge(master\_1p\_syns\_gr, syns\_controls\_1p, all = TRUE, suffix = c('\_test', '\_control'), by = 'gene')

merged\_data\_syns\_1p$hom\_ref\_control\[is.na(merged\_data\_syns\_1p$hom\_ref\_control)\] <- merged\_data\_syns\_1p$n\_variants\_test\[is.na(merged\_data\_syns\_1p$hom\_ref\_control)\] \* 496

fisher.test(matrix(hom\_ref\*2 + het, het + 2\* hom\_alt,)

\# missense+ptv variants:

merged\_data\_mis\_ptv\_1p <- merge(master\_1p\_mis\_ptv\_gr, mis\_ptv\_controls\_1p, all = TRUE, suffix = c('\_test', '\_control'), by = 'gene')

merged\_data\_mis\_ptv\_1p\[is.na(merged\_data\_mis\_ptv\_1p)\] = 0

### \# Allele based fisher test

\# synonymous variants:

merged\_data\_syns\_fisher <- merged\_data\_syns\_1p %>%

  rowwise() %>%

  mutate(

    fisher\_p\_value = fisher.test(matrix(c(

      (het\_control + hom\_alt\_control \* 2),

      (hom\_ref\_control \* 2 + het\_control),

      (het\_test + hom\_alt\_test \* 2),

      (hom\_ref\_test \* 2 + het\_test)

    ), nrow = 2, byrow = TRUE))$p.value,

    odds\_ratio = fisher.test(matrix(c(

      (het\_control + hom\_alt\_control \* 2),

      (hom\_ref\_control \* 2 + het\_control),

      (het\_test + hom\_alt\_test \* 2),

      (hom\_ref\_test \* 2 + het\_test)

    ), nrow = 2, byrow = TRUE))$estimate)

\# missense+ptv variants:

merged\_data\_mis\_ptv\_fisher <- merged\_data\_mis\_ptv\_1p %>%

  rowwise() %>%

  mutate(

    fisher\_p\_value = fisher.test(matrix(c(

      (het\_control + hom\_alt\_control \* 2),

      (hom\_ref\_control \* 2 + het\_control),

      (het\_test + hom\_alt\_test \* 2),

      (hom\_ref\_test \* 2 + het\_test)

    ), nrow = 2, byrow = TRUE))$p.value,

    odds\_ratio = fisher.test(matrix(c(

      (het\_control + hom\_alt\_control \* 2),

      (hom\_ref\_control \* 2 + het\_control),

      (het\_test + hom\_alt\_test \* 2),

      (hom\_ref\_test \* 2 + het\_test)

    ), nrow = 2, byrow = TRUE))$estimate

  )

### \# Calculate p value distributions for visualization

\# synonymous variants:

merged\_data\_syns\_fisher$fisher\_p\_value\[merged\_data\_syns\_fisher$fisher\_p\_value == 0\] <- .Machine$double.xmin

merged\_data\_syns\_fisher$fisher\_p\_value <- as.numeric(merged\_data\_syns\_fisher$fisher\_p\_value)

merged\_data\_syns\_fisher$neg\_log\_p <- -log10(merged\_data\_syns\_fisher$fisher\_p\_value)

merged\_data\_syns\_fisher$theoretical <- -log10((rank(merged\_data\_syns\_fisher$fisher\_p\_value) - 0.5) / length(merged\_data\_syns\_fisher$fisher\_p\_value))

\# missense+ptv variants:

merged\_data\_mis\_ptv\_fisher$fisher\_p\_value\[merged\_data\_mis\_ptv\_fisher$fisher\_p\_value == 0\] <- .Machine$double.xmin

merged\_data\_mis\_ptv\_fisher$fisher\_p\_value <- as.numeric(merged\_data\_mis\_ptv\_fisher$fisher\_p\_value)

merged\_data\_mis\_ptv\_fisher$neg\_log\_p <- -log10(merged\_data\_mis\_ptv\_fisher$fisher\_p\_value)

merged\_data\_mis\_ptv\_fisher$theoretical <- -log10((rank(merged\_data\_mis\_ptv\_fisher$fisher\_p\_value) - 0.5) / length(merged\_data\_mis\_ptv\_fisher$fisher\_p\_value))

### \# Save the result table

\# synonymous variants:

write.table(merged\_data\_syns\_fisher, "for\_qpplot\_carriers\_syns\_1p\_new\_p\_value.tsv", sep="\\t")

\# missense+ptv variants:

write.table(merged\_data\_mis\_ptv\_fisher, "for\_qpplot\_carriers\_mis\_ptv\_1p\_new\_p\_value.tsv", sep="\\t")

### \# Genotype based Fisher test

\# synonymous variants:

fisher\_p\_values\_syns <- numeric(nrow(merged\_data\_syns\_1p))

odds\_ratios\_syns <- numeric(nrow(merged\_data\_syns\_1p))

total\_control <- 496

total\_gbr <- 91

for (i in 1:nrow(merged\_data\_syns\_1p)) {

  het\_control <- merged\_data\_syns\_1p$het\_control\[i\]

  het\_test <- merged\_data\_syns\_1p$het\_test\[i\]

  remaining\_control <- total\_control - het\_control

  remaining\_gbr <- total\_gbr - het\_test

    if (any(c(het\_control, het\_test, remaining\_control, remaining\_gbr) < 0)) {

    next

  }

    matrix\_data <- matrix(c(het\_control, remaining\_control, het\_test, remaining\_gbr), nrow = 2)

    if (any(rowSums(matrix\_data) == 0) || any(colSums(matrix\_data) == 0)) {

    next

  }

  fisher\_test <- fisher.test(matrix\_data)

  fisher\_p\_values\_syns\[i\] <- fisher\_test$p.value

  odds\_ratios\_syns\[i\] <- ifelse(is.finite(fisher\_test$estimate), fisher\_test$estimate, NA)

}

results\_syns\_genes\_fisher <- data.frame(

  gene = merged\_data\_syns\_1p$gene,  fisher\_p\_value = fisher\_p\_values\_syns,

  odds\_ratio = odds\_ratios\_syns)

\# missense+ptv variants:

fisher\_p\_values\_mis\_ptv <- numeric(nrow(merged\_data\_mis\_ptv\_1p))

odds\_ratios\_mis\_ptv <- numeric(nrow(merged\_data\_mis\_ptv\_1p))

total\_control <- 496

total\_gbr <- 91

for (i in 1:nrow(merged\_data\_syns\_1p)) {

  het\_control <- merged\_data\_syns\_1p$het\_control\[i\]

  het\_test <- merged\_data\_syns\_1p$het\_test\[i\]

  remaining\_control <- total\_control - het\_control

  remaining\_gbr <- total\_gbr - het\_test

    if (any(c(het\_control, het\_test, remaining\_control, remaining\_gbr) < 0)) {

    next

  }

    matrix\_data <- matrix(c(het\_control, remaining\_control, het\_test, remaining\_gbr), nrow = 2)

    if (any(rowSums(matrix\_data) == 0) || any(colSums(matrix\_data) == 0)) {

    next

  }

  fisher\_test <- fisher.test(matrix\_data)

  fisher\_p\_values\_syns\[i\] <- fisher\_test$p.value

  odds\_ratios\_syns\[i\] <- ifelse(is.finite(fisher\_test$estimate), fisher\_test$estimate, NA)

}

results\_mis\_ptv\_genes\_fisher <- data.frame(

  gene = merged\_data\_mis\_ptv\_1p$gene,  fisher\_p\_value = fisher\_p\_values\_mis\_ptv,

  odds\_ratio = odds\_ratios\_mis\_ptv)

### \# Calculate p value distributions for visualization

\# synonymous variants:

results\_syns\_genes\_fisher$fisher\_p\_value\[results\_syns\_genes\_fisher$fisher\_p\_value == 0\] <- .Machine$double.xmin

results\_syns\_genes\_fisher$fisher\_p\_value <- as.numeric(results\_syns\_genes\_fisher$fisher\_p\_value)

results\_syns\_genes\_fisher$neg\_log\_p <- -log10(results\_syns\_genes\_fisher$fisher\_p\_value)

results\_syns\_genes\_fisher$theoretical <- -log10((rank(results\_syns\_genes\_fisher$fisher\_p\_value) - 0.5) / length(results\_syns\_genes\_fisher$fisher\_p\_value))

\# missense+ptv variants:

results\_mis\_ptv\_genes\_fisher$fisher\_p\_value\[results\_mis\_ptv\_genes\_fisher$fisher\_p\_value == 0\] <- .Machine$double.xmin

results\_mis\_ptv\_genes\_fisher$fisher\_p\_value <- as.numeric(results\_mis\_ptv\_genes\_fisher$fisher\_p\_value)

results\_mis\_ptv\_genes\_fisher$neg\_log\_p <- -log10(results\_mis\_ptv\_genes\_fisher$fisher\_p\_value)

results\_mis\_ptv\_genes\_fisher$theoretical <- -log10((rank(results\_mis\_ptv\_genes\_fisher$fisher\_p\_value) - 0.5) / length(results\_mis\_ptv\_genes\_fisher$fisher\_p\_value))

### \# Save the result table

\# synonymous variants:

write.table(results\_syns\_genes\_fisher, "for\_qpplot\_genes\_syns\_1p\_new\_p\_value.tsv", sep="\\t")

\# missense+ptv variants:

write.table(results\_mis\_ptv\_genes\_fisher, "for\_qpplot\_genes\_mis\_ptv\_1p\_new\_p\_value.tsv", sep="\\t")

### QQPlots

import pandas as pd

import numpy as np

import scipy.stats as stats

import matplotlib.pyplot as plt

results\_df = pd.read\_csv("input table" ,sep = "\\t")

print(results\_df)

expected = results\_df\['theoretical'\]

observed = results\_df\['neg\_log\_p'\]

plt.figure(figsize=(6, 6))

plt.scatter(expected, observed, edgecolor='black') plt.plot(\[expected.min(), expected.max()\], \[expected.min(), expected.max()\], color='red', linestyle='--')

plt.xlabel("Expected -log10(p-value)")

plt.ylabel("Observed -log10(p-value)")

plt.title("QQ-plot of p-values")

plt.show()